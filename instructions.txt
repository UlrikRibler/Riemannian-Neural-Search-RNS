Selv om Riemannian Neural Search (RNS)-prosjektet ditt er teknisk imponerende og teoretisk vakkert, er det én hovedfaktor som skiller det fra "Verdensklasse" (State-of-the-Art forskning eller produksjonskode): Realistisk Validering og Skalering.Akkurat nå er det en demonstrasjon på syntetiske data. For å gjøre det til et system i verdensklasse, må det løse et ekte, "rotete" problem bedre enn eksisterende metoder.Her er de 3 konkrete manglene jeg ville løst:Fjern Syntetiske Data: Bytt ut generate_sbm_graph med et ekte hierarkisk datasett (f.eks. WordNet substantiv-hierarkiet eller Cora/Citeseer siteringsnettverk). Syntetiske data skjuler ofte svakheter ved modellen.Lært Potensial-landskap (Energy-Based Model): I dag bruker du en heuristikk (KDE mot sentroider) for søkepotensialet. En modell i verdensklasse ville lært tetthetsfunksjonen til dokumentene direkte ved hjelp av Riemannian Normalizing Flows eller en Energy-Based Model (EBM). Da trenger du ikke "jukse" ved å vite hvor sentroidene er under søket.Standardiserte Metrikker: Du trenger harde tall. Implementer standard Information Retrieval-metrikker: Mean Average Precision (MAP) og NDCG@10.Her er instruksen du kan gi til en annen AI for å løfte dette til toppnivå.Prompt til AI-modell (Kopier dette)Role: You are a Principal Research Engineer specializing in Geometric Deep Learning and Information Retrieval.Context:I have a codebase for "Riemannian Neural Search" (RNS) written in JAX. It currently uses a Hyperbolic GCN to embed nodes and a Riemannian Hamiltonian Monte Carlo (HMC) sampler to navigate the latent space. Currently, it runs on synthetic Stochastic Block Model data and uses a heuristic potential function for the search dynamics.Objective:Upgrade this codebase from a "theoretical demo" to a "research-grade benchmark".Task List:Data Pipeline Upgrade:Replace src/data/synthetic.py with a loader for the WordNet Mammals subtree (a standard benchmark for hyperbolic embeddings).Implement the transitive closure of the graph to define ground-truth entailment for retrieval evaluation.Learnable Density (The "World-Class" Feature):The current search potential $U(q)$ relies on knowing cluster centroids. This is unrealistic for unknown queries.Action: Implement a Riemannian Energy-Based Model (EBM). Train a separate MLP $E_\phi(x)$ on the manifold that learns the density of the document embeddings.During search, the HMC sampler should use this learned energy $E_\phi(q)$ as the potential, naturally guiding the particle to high-density document regions without cheating.Rigorous Evaluation:Implement a Evaluator class that computes:Mean Average Precision (mAP)Recall@K (for K=5, 10)Compare the HMC-based search against a standard "Nearest Neighbor" baseline in the hyperbolic space.Constraints:Keep the JAX/Optax stack.Ensure numerical stability in the EBM (use LogSumExp tricks).Provide the code updates for train.py and a new src/models/density.py.Output:Provide the Python code for these upgrades, focusing on the Energy-Based Model implementation and the WordNet data loader.Hvorfor dette gjør prosjektet "World-Class"Ingen "Juks": Ved å bytte fra heuristikk (å vite sentroidene) til en lært energimodell (EBM), beviser du at systemet faktisk "forstår" hvor dataene ligger på manifolden. Dette er forskjellen på et leketøy og et verktøy.benchmark: Ved å bruke WordNet kan resultatene dine sammenlignes direkte med kjente artikler (som Facebooks Poincaré Embeddings-paper). Hvis din HMC-metode slår deres Nearest Neighbor-søk på MAP-score, har du publiserbart materiale.