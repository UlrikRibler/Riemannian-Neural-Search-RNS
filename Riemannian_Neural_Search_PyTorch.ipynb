{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian Neural Search (PyTorch Implementation)\n",
    "\n",
    "This notebook implements the **Riemannian Neural Search (RNS)** system completely in **PyTorch**. \n",
    "\n",
    "It demonstrates:\n",
    "1.  **Hyperbolic Geometry:** Poincaré Ball math in PyTorch.\n",
    "2.  **The Encoder:** A Hyperbolic Graph Convolutional Network (HGCN) with learnable curvature.\n",
    "3.  **The Physicist Ranker:** A Riemannian Hamiltonian Monte Carlo (HMC) sampler that uses physics simulations for search retrieval.\n",
    "4.  **Experiment:** Searching for an ambiguous query (\"Bank\") in a synthetic Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Geometry: Poincaré Ball Manifold\n",
    "\n",
    "We implement the math for the Poincaré Ball model with curvature $c$. \n",
    "Operations include:\n",
    "*   `mobius_add`: Adding vectors in curved space.\n",
    "*   `dist`: Geodesic distance.\n",
    "*   `exp_map0` / `log_map0`: Mapping between Euclidean Tangent Space (at origin) and the Manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoincareBall:\n",
    "    def __init__(self, c=1.0):\n",
    "        self.c = c\n",
    "        # Numerical stability epsilon\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def lambda_x(self, x):\n",
    "        \"\"\"Conformal factor: 2 / (1 - c * ||x||^2)\"""\n",
    "        x_norm_sq = torch.sum(x ** 2, dim=-1, keepdim=True)\n",
    "        # Clip for stability\n",
    "        x_norm_sq = torch.clamp(x_norm_sq, max=1.0/self.c - self.eps)\n",
    "        return 2.0 / (1.0 - self.c * x_norm_sq)\n",
    "\n",
    "    def mobius_add(self, x, y):\n",
    "        \"\"\"Möbius addition: x (+) y\"""\n",
    "        x2 = torch.sum(x * x, dim=-1, keepdim=True)\n",
    "        y2 = torch.sum(y * y, dim=-1, keepdim=True)\n",
    "        xy = torch.sum(x * y, dim=-1, keepdim=True)\n",
    "        \n",
    "        num = (1 + 2 * self.c * xy + self.c * y2) * x + (1 - self.c * x2) * y\n",
    "        denom = 1 + 2 * self.c * xy + self.c**2 * x2 * y2\n",
    "        return num / (denom + 1e-15)\n",
    "\n",
    "    def dist(self, x, y):\n",
    "        \"\"\"Geodesic Distance\"""\n",
    "        diff = self.mobius_add(-x, y)\n",
    "        diff_norm = torch.norm(diff, dim=-1, keepdim=True)\n",
    "        # Clip to avoid NaNs\n",
    "        diff_norm = torch.clamp(diff_norm, min=1e-15, max=1.0/math.sqrt(self.c) - self.eps)\n",
    "        \n",
    "        res = (2.0 / math.sqrt(self.c)) * torch.atanh(math.sqrt(self.c) * diff_norm)\n",
    "        return res\n",
    "\n",
    "    def exp_map0(self, v):\n",
    "        \"\"\"Exponential map at origin: Tangent(Euclidean) -> Manifold\"""\n",
    "        v_norm = torch.norm(v, dim=-1, keepdim=True)\n",
    "        v_norm = torch.clamp(v_norm, min=1e-15)\n",
    "        \n",
    "        # res = tanh(sqrt(c) * ||v||) * (v / (sqrt(c) * ||v||))\n",
    "        res = torch.tanh(math.sqrt(self.c) * v_norm) * (v / (math.sqrt(self.c) * v_norm))\n",
    "        return res\n",
    "\n",
    "    def log_map0(self, y):\n",
    "        \"\"\"Log map at origin: Manifold -> Tangent(Euclidean)\"""\n",
    "        y_norm = torch.norm(y, dim=-1, keepdim=True)\n",
    "        y_norm = torch.clamp(y_norm, min=1e-15, max=1.0/math.sqrt(self.c) - self.eps)\n",
    "        \n",
    "        res = (1.0 / math.sqrt(self.c)) * torch.atanh(math.sqrt(self.c) * y_norm) * (y / y_norm)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Encoder: Hyperbolic GCN\n",
    "\n",
    "We implement the **HGCN Layer** using the \"Tangent Space Aggregation\" strategy:\n",
    "1.  **Lift** features to Tangent space ($\\log_0$).\n",
    "2.  **Agg**regate neighbors (matrix mult with Adjacency).\n",
    "3.  **Lin**ear transform (Euclidean weights).\n",
    "4.  **Act**ivation (ReLU).\n",
    "5.  **Proj**ect back to Manifold ($\\exp_0$).\n",
    "\n",
    "We also make the curvature `c` a learnable parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, c=1.0):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.c = c\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, h, adj, manifold):\n",
    "        # 1. Lift to Tangent Space (Log Map)\n",
    "        h_tan = manifold.log_map0(h)\n",
    "        \n",
    "        # 2. Aggregation (Graph Conv)\n",
    "        # adj shape (N, N), h_tan (N, D)\n",
    "        h_agg = torch.mm(adj, h_tan)\n",
    "        \n",
    "        # 3. Linear Transform (in Euclidean Tangent Space)\n",
    "        h_trans = self.linear(h_agg)\n",
    "        \n",
    "        # 4. Activation\n",
    "        h_act = torch.relu(h_trans)\n",
    "        \n",
    "        # 5. Project back (Exp Map)\n",
    "        h_out = manifold.exp_map0(h_act)\n",
    "        return h_out\n",
    "\n",
    "class HyperbolicGCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        # Learnable curvature\n",
    "        self.c_param = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        self.layer1 = HGCNLayer(in_dim, hidden_dim)\n",
    "        self.layer2 = HGCNLayer(hidden_dim, out_dim)\n",
    "        \n",
    "    def get_manifold(self):\n",
    "        # Ensure c is positive\n",
    "        c = torch.nn.functional.softplus(self.c_param)\n",
    "        return PoincareBall(c.item())\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        manifold = self.get_manifold()\n",
    "        \n",
    "        # Assume input x is Euclidean features -> map to manifold first\n",
    "        h = manifold.exp_map0(x)\n",
    "        \n",
    "        h = self.layer1(h, adj, manifold)\n",
    "        h = self.layer2(h, adj, manifold)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Physicist Ranker: Riemannian HMC\n",
    "\n",
    "This is the core innovation. We define a sampler that explores the search space using Hamiltonian dynamics.\n",
    "\n",
    "**Hamiltonian:** $H(q, p) = U(q) + \frac{1}{2} p^T p$
",
    "*(Simplified Kinetic Energy assuming isotropic metric for this demo)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiemannianHMC:\n",
    "    def __init__(self, potential_fn, step_size=0.05, n_steps=10):\n",
    "        self.potential_fn = potential_fn\n",
    "        self.step_size = step_size\n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "    def kinetic_energy(self, p):\n",
    "        # Simplified Euclidean kinetic energy for demo\n",
    "        return 0.5 * torch.sum(p**2)\n",
    "    \n",
    "    def hamiltonian(self, q, p):\n",
    "        return self.potential_fn(q) + self.kinetic_energy(p)\n",
    "    \n",
    "    def step(self, q_init):\n",
    "        \"\"\"Performs one HMC step\"""\n",
    "        q = q_init.clone().detach().requires_grad_(True)\n",
    "        p = torch.randn_like(q)\n",
    "        \n",
    "        curr_H = self.hamiltonian(q, p)\n",
    "        \n",
    "        # Leapfrog Integrator\n",
    "        dt = self.step_size\n",
    "        q_new = q.clone()\n",
    "        p_new = p.clone()\n",
    "        \n",
    "        # Gradients for first half-step of momentum\n",
    "        U = self.potential_fn(q_new)\n",
    "        grad_U = torch.autograd.grad(U, q_new)[0]\n",
    "        p_new = p_new - 0.5 * dt * grad_U\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            # Full step position\n",
    "            q_new = q_new + dt * p_new\n",
    "            \n",
    "            # Re-calculate Gradient at new position\n",
    "            # (Need to detach and re-enable grad to track new graph)\n",
    "            q_new = q_new.detach().requires_grad_(True)\n",
    "            U = self.potential_fn(q_new)\n",
    "            grad_U = torch.autograd.grad(U, q_new)[0]\n",
    "            \n",
    "            # Full step momentum (except last)\n",
    "            if i != self.n_steps - 1:\n",
    "                p_new = p_new - dt * grad_U\n",
    "                \n",
    "        # Last half-step momentum\n",
    "        p_new = p_new - 0.5 * dt * grad_U\n",
    "        \n",
    "        # Metropolis Accept/Reject\n",
    "        prop_H = self.hamiltonian(q_new, p_new)\n",
    "        \n",
    "        # Standard HMC acceptance\n",
    "        accept_prob = torch.exp(curr_H - prop_H)\n",
    "        if torch.rand(1) < accept_prob:\n",
    "            return q_new.detach()\n",
    "        else:\n",
    "            return q_init.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulation Setup\n",
    "\n",
    "We create a synthetic graph with 3 clusters representing topics (e.g., Nature, Finance, Sport).\n",
    "We will then train the HGCN to embed this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sbm_data(num_nodes=100, num_clusters=3, dim=16):\n",
    "    # Assignments\n",
    "    nodes_per = num_nodes // num_clusters\n",
    "    labels = torch.cat([torch.full((nodes_per,), i) for i in range(num_clusters)])\n",
    "    # Remainder\n",
    "    if len(labels) < num_nodes:\n",
    "        labels = torch.cat([labels, torch.full((num_nodes - len(labels),), num_clusters-1)])\n",
    "        \n",
    "    # Features (Cluster centers + noise)\n",
    "    centers = torch.randn(num_clusters, dim)\n",
    "    features = centers[labels] + torch.randn(num_nodes, dim) * 0.1\n",
    "    \n",
    "    # Adjacency (High prob inside cluster, low prob outside)\n",
    "    adj = torch.eye(num_nodes)\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i+1, num_nodes):\n",
    "            prob = 0.3 if labels[i] == labels[j] else 0.01\n",
    "            if torch.rand(1) < prob:\n",
    "                adj[i, j] = 1.0\n",
    "                adj[j, i] = 1.0\n",
    "                \n",
    "    # Normalize Adj (Row norm)\n",
    "    deg = torch.sum(adj, dim=1, keepdim=True)\n",
    "    adj_norm = adj / deg\n",
    "    \n",
    "    return features, adj_norm, labels\n",
    "\n",
    "features, adj, labels = generate_sbm_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "We train using a **Contrastive Loss**: pull connected nodes together in hyperbolic space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "model = HyperbolicGCN(in_dim=16, hidden_dim=32, out_dim=2) # 2D output for plotting\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train(epochs=200):\n",
    "    print(\"Starting Training...\")\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings = model(features, adj)\n",
    "        manifold = model.get_manifold()\n",
    "        \n",
    "        # Simplified Loss: Distance to Cluster Center\n",
    "        # (Instead of full pair-wise InfoNCE for demo speed)\n",
    "        loss = 0\n",
    "        for i in range(3):\n",
    "            mask = labels == i\n",
    "            cluster_embs = embeddings[mask]\n",
    "            if len(cluster_embs) > 0:\n",
    "                # Calculate approximate center (Euclidean mean in Poincare is rough but works for loss)\n",
    "                # Better: generalized mean. We use simple mean for demo.\n",
    "                center = torch.mean(cluster_embs, dim=0, keepdim=True)\n",
    "                # Minimize distance to center\n",
    "                dists = manifold.dist(cluster_embs, center)\n",
    "                loss += torch.mean(dists)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            c_val = torch.nn.functional.softplus(model.c_param).item()\n",
    "            print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Curvature: {c_val:.4f}\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The \"Physicist\" Search Simulation\n",
    "\n",
    "We simulate an **Ambiguous Query** (e.g., \"Bank\"). \n",
    "*   It relates to Cluster 0 (Finance) and Cluster 1 (Nature/River).\n",
    "*   We define the Potential Energy $U(q)$ to be low near both cluster centers.\n",
    "*   We drop the HMC particle and watch it move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get Trained Embeddings\n",
    "final_embeddings = model(features, adj).detach()\n",
    "manifold = model.get_manifold()\n",
    "\n",
    "# 2. Define Ambiguous Target (Centroids of Cluster 0 and 1)\n",
    "c0 = torch.mean(final_embeddings[labels==0], dim=0)\n",
    "c1 = torch.mean(final_embeddings[labels==1], dim=0)\n",
    "\n",
    "# 3. Define Potential Function U(q)\n",
    "def search_potential(q):\n",
    "    # Unpack for broadcasting\n",
    "    q_in = q.unsqueeze(0)\n",
    "    target0 = c0.unsqueeze(0)\n",
    "    target1 = c1.unsqueeze(0)\n",
    "    \n",
    "    d0 = manifold.dist(q_in, target0)\n",
    "    d1 = manifold.dist(q_in, target1)\n",
    "    \n",
    "    # SoftMin Potential: Deep valleys at both targets\n",
    "    # U = -log( exp(-d0^2) + exp(-d1^2) )\n",
    "    energy = -torch.log(torch.exp(-4.0 * d0**2) + torch.exp(-4.0 * d1**2) + 1e-9)\n",
    "    return energy.squeeze()\n",
    "\n",
    "# 4. Initialize HMC\n",
    "hmc = RiemannianHMC(search_potential, step_size=0.1, n_steps=5)\n",
    "\n",
    "# 5. Run Chain\n",
    "samples = []\n",
    "q = torch.zeros(2) # Start at origin\n",
    "\n",
    "print(\"Running HMC Search...\")\n",
    "for _ in range(200):\n",
    "    q = hmc.step(q)\n",
    "    samples.append(q.numpy())\n",
    "    \n",
    "samples = np.array(samples)\n",
    "print(\"Search Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualization\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Draw Boundary\n",
    "boundary_radius = 1.0 / math.sqrt(manifold.c)\n",
    "circle = plt.Circle((0, 0), boundary_radius, color='black', fill=False, linestyle='--', label='Boundary')\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "# Draw Documents\n",
    "colors = ['r', 'g', 'b']\n",
    "for i in range(3):\n",
    "    mask = labels == i\n",
    "    pts = final_embeddings[mask]\n",
    "    plt.scatter(pts[:, 0], pts[:, 1], c=colors[i], alpha=0.5, label=f'Cluster {i}')\n",
    "\n",
    "# Draw Targets\n",
    "plt.plot(c0[0], c0[1], 'rx', markersize=12, markeredgewidth=3, label='Target A')\n",
    "plt.plot(c1[0], c1[1], 'gx', markersize=12, markeredgewidth=3, label='Target B')\n",
    "\n",
    "# Draw Search Trajectory\n",
    "plt.plot(samples[:, 0], samples[:, 1], 'k.-', linewidth=1, alpha=0.6, label='HMC Searcher')\n",
    "\n",
    "plt.xlim(-1.1*boundary_radius, 1.1*boundary_radius)\n",
    "plt.ylim(-1.1*boundary_radius, 1.1*boundary_radius)\n",
    "plt.legend()\n",
    "plt.title(f"Riemannian Neural Search (PyTorch)\nCurvature c={manifold.c:.2f}")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
